{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d080b7ca",
   "metadata": {},
   "source": [
    "Aerilio ai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218aab2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s query based on the context below.\\nIf you cannot answer the question using the\\nprovided information answer with \"I don\\'t know\".\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = \"\"\"\n",
    "Answer the user's query based on the context below.\n",
    "If you cannot answer the question using the\n",
    "provided information answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt),\n",
    "    (\"user\", \"{query}\"),\n",
    "])\n",
    "prompt_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83393247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s query based on the context below.\\nIf you cannot answer the question using the\\nprovided information answer with \"I don\\'t know\".\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(prompt),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "])\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0190affb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s query based on the context below.\\nIf you cannot answer the question using the\\nprovided information answer with \"I don\\'t know\".\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x000001F5021825C0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F502182EC0>, root_client=<openai.OpenAI object at 0x000001F502182BC0>, root_async_client=<openai.AsyncOpenAI object at 0x000001F502183F40>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\n",
    "    \"Enter OpenAI API Key: \"\n",
    ")\n",
    "\n",
    "openai_model = \"gpt-4o-mini\"\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=openai_model)\n",
    "pipeline = prompt_template | llm\n",
    "pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c8b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Aurelio AI is an AI company that develops tooling for AI engineers, focusing on language AI. They have expertise in building AI agents and information retrieval. The company is known for several open source frameworks, including Semantic Router and Semantic Chunkers, and offers an AI Platform that provides engineers with tools to build with AI. Additionally, they provide development services to help other organizations bring their AI technology to market.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 183, 'total_tokens': 264, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_11f3029f6b', 'id': 'chatcmpl-CiuduHhhcNE0kBkcKsVXxdo32GfiR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--7194edc7-89ef-4c7f-86e3-ac99bceec658-0', usage_metadata={'input_tokens': 183, 'output_tokens': 81, 'total_tokens': 264, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"\"\"Aurelio AI is an AI company developing tooling for AI\n",
    "engineers. Their focus is on language AI with the team having strong\n",
    "expertise in building AI agents and a strong background in\n",
    "information retrieval.\n",
    "\n",
    "The company is behind several open source frameworks, most notably\n",
    "Semantic Router and Semantic Chunkers. They also have an AI\n",
    "Platform providing engineers with tooling to help them build with\n",
    "AI. Finally, the team also provides development services to other\n",
    "organizations to help them bring their AI tech to market.\n",
    "\n",
    "Aurelio AI became LangChain Experts in September 2024 after a long\n",
    "track record of delivering AI solutions built with the LangChain\n",
    "ecosystem.\"\"\"\n",
    "\n",
    "query = \"what does Aurelio AI do?\"\n",
    "pipeline.invoke({\"query\": query, \"context\": context})\n",
    "context = \"\"\"Aurelio AI is an AI company developing tooling for AI\n",
    "engineers. Their focus is on language AI with the team having strong\n",
    "expertise in building AI agents and a strong background in\n",
    "information retrieval.\n",
    "\n",
    "The company is behind several open source frameworks, most notably\n",
    "Semantic Router and Semantic Chunkers. They also have an AI\n",
    "Platform providing engineers with tooling to help them build with\n",
    "AI. Finally, the team also provides development services to other\n",
    "organizations to help them bring their AI tech to market.\n",
    "\n",
    "Aurelio AI became LangChain Experts in September 2024 after a long\n",
    "track record of delivering AI solutions built with the LangChain\n",
    "ecosystem.\"\"\"\n",
    "\n",
    "query = \"what does Aurelio AI do?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "098f2a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Response: content='Ah, the transformer! The shiny new toy in the world of machine learning that everyone seems to be raving about. It’s a type of model architecture that was introduced in a paper called \"Attention is All You Need\" back in 2017. Because, you know, who needs recurrent neural networks when you can just throw attention mechanisms at everything?\\n\\nTransformers are particularly great for handling sequential data, like text, without the need for the sequential processing that RNNs (Recurrent Neural Networks) require. Instead, they use something called self-attention, which allows the model to weigh the importance of different words in a sentence relative to each other. So, instead of reading a sentence word by word, it can look at the whole thing at once. Revolutionary, right?\\n\\nThey consist of an encoder-decoder structure, where the encoder processes the input data and the decoder generates the output. But let’s be real, most of the time, people just use the encoder part for tasks like text classification or the decoder part for generating text, because who has time for all that complexity?\\n\\nIn short, transformers are like the Swiss Army knife of machine learning: versatile, powerful, and a bit overhyped. But hey, if you want to build a state-of-the-art model for natural language processing, you might as well hop on the transformer bandwagon!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 274, 'prompt_tokens': 28, 'total_tokens': 302, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b547601dbd', 'id': 'chatcmpl-Civ6h2B11hIcIloQbiC7TL1NAQ0oz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--3cb33644-aa7f-494b-bbf0-6200fd07384b-0' usage_metadata={'input_tokens': 28, 'output_tokens': 274, 'total_tokens': 302, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Aurelio AI is an AI company that develops tooling for AI engineers, focusing on language AI. They have expertise in building AI agents and information retrieval. The company is known for several open source frameworks, including Semantic Router and Semantic Chunkers, and offers an AI Platform that provides engineers with tools to build with AI. Additionally, they provide development services to help other organizations bring their AI technology to market.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 183, 'total_tokens': 264, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b547601dbd', 'id': 'chatcmpl-Civ6pPiYQf9s5Er15AGk4DSmskqrv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f363c7ac-cf37-4a07-962c-1a1f716e83e4-0', usage_metadata={'input_tokens': 183, 'output_tokens': 81, 'total_tokens': 264, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialise models\n",
    "model_openai = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Messages\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful but sarcastic assistant.\"),\n",
    "    HumanMessage(content=\"What is a transformer in machine learning?\"),\n",
    "]\n",
    "\n",
    "# Send to both models\n",
    "response_openai = model_openai.invoke(messages)\n",
    "\n",
    "print(\"OpenAI Response:\", response_openai)\n",
    "pipeline.invoke({\"query\": query, \"context\": context})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a131b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\"),\n",
    "])\n",
    "example_prompt\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Can you explain gravity?\",\n",
    "        \"output\": (\n",
    "            \"## Gravity\\n\\n\"\n",
    "            \"Gravity is one of the fundamental forces in the universe.\\n\\n\"\n",
    "            \"### Discovery\\n\\n\"\n",
    "            \"* Gravity was first discovered by Sir Isaac Newton in the late 17th \"\n",
    "            \"century.\\n\"\n",
    "            \"* It was said that Newton theorized about gravity after seeing an apple \"\n",
    "            \"fall from a tree.\\n\\n\"\n",
    "            \"### In General Relativity\\n\\n\"\n",
    "            \"* Gravity is described as the curvature of spacetime.\\n\"\n",
    "            \"* The more massive an object is, the more it curves spacetime.\\n\"\n",
    "            \"* This curvature is what causes objects to fall towards each other.\\n\\n\"\n",
    "            \"### Gravitons\\n\\n\"\n",
    "            \"* Gravitons are hypothetical particles that mediate the force of gravity.\\n\"\n",
    "            \"* They have not yet been detected.\\n\\n\"\n",
    "            \"**To conclude**, Gravity is a fascinating topic and has been studied \"\n",
    "            \"extensively since the time of Newton.\\n\\n\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the capital of France?\",\n",
    "        \"output\": (\n",
    "            \"## France\\n\\n\"\n",
    "            \"The capital of France is Paris.\\n\\n\"\n",
    "            \"### Origins\\n\\n\"\n",
    "            \"* The name Paris comes from the Latin word \\\"Parisini\\\" which referred to \"\n",
    "            \"a Celtic people living in the area.\\n\"\n",
    "            \"* The Romans named the city Lutetia, which means \\\"the place where the \"\n",
    "            \"river turns\\\".\\n\"\n",
    "            \"* The city was renamed Paris in the 3rd century BC by the Celtic-speaking \"\n",
    "            \"Parisii tribe.\\n\\n\"\n",
    "            \"**To conclude**, Paris is highly regarded as one of the most beautiful \"\n",
    "            \"cities in the world and is one of the world's greatest cultural and \"\n",
    "            \"economic centres.\\n\\n\"\n",
    "        )\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7d7643e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Can you explain gravity?\n",
      "AI: ## Gravity\n",
      "\n",
      "Gravity is one of the fundamental forces in the universe.\n",
      "\n",
      "### Discovery\n",
      "\n",
      "* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\n",
      "* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\n",
      "\n",
      "### In General Relativity\n",
      "\n",
      "* Gravity is described as the curvature of spacetime.\n",
      "* The more massive an object is, the more it curves spacetime.\n",
      "* This curvature is what causes objects to fall towards each other.\n",
      "\n",
      "### Gravitons\n",
      "\n",
      "* Gravitons are hypothetical particles that mediate the force of gravity.\n",
      "* They have not yet been detected.\n",
      "\n",
      "**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\n",
      "\n",
      "\n",
      "Human: What is the capital of France?\n",
      "AI: ## France\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "### Origins\n",
      "\n",
      "* The name Paris comes from the Latin word \"Parisini\" which referred to a Celtic people living in the area.\n",
      "* The Romans named the city Lutetia, which means \"the place where the river turns\".\n",
      "* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\n",
      "\n",
      "**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world's greatest cultural and economic centres.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "# here is the formatted prompt\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63e96c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Can you explain gravity?\\nAI: ## Gravity\\n\\nGravity is one of the fundamental forces in the universe.\\n\\n### Discovery\\n\\n* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\\n* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\\n\\n### In General Relativity\\n\\n* Gravity is described as the curvature of spacetime.\\n* The more massive an object is, the more it curves spacetime.\\n* This curvature is what causes objects to fall towards each other.\\n\\n### Gravitons\\n\\n* Gravitons are hypothetical particles that mediate the force of gravity.\\n* They have not yet been detected.\\n\\n**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\\n\\n\\nHuman: What is the capital of France?\\nAI: ## France\\n\\nThe capital of France is Paris.\\n\\n### Origins\\n\\n* The name Paris comes from the Latin word \"Parisini\" which referred to a Celtic people living in the area.\\n* The Romans named the city Lutetia, which means \"the place where the river turns\".\\n* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\\n\\n**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world\\'s greatest cultural and economic centres.\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "out = few_shot_prompt.format()\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93953bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, the transformer! The shiny new toy in the world of machine learning that everyone seems to be raving about. It’s a type of model architecture that was introduced in a paper called \"Attention is All You Need\" back in 2017. Because, you know, who needs recurrent neural networks when you can just throw attention mechanisms at everything?\\n\\nTransformers are particularly great for handling sequential data, like text, without the need for the sequential processing that RNNs (Recurrent Neural Networks) require. Instead, they use something called self-attention, which allows the model to weigh the importance of different words in a sentence relative to each other. So, instead of reading a sentence word by word, it can look at the whole thing at once. Revolutionary, right?\\n\\nThey consist of an encoder and a decoder. The encoder processes the input data and the decoder generates the output. But let’s be real, most of the time, people just use the encoder part for tasks like text classification or the decoder part for generating text, because who has time for both?\\n\\nTransformers have become the backbone of many state-of-the-art models, like BERT and GPT, which are now the go-to for everything from chatbots to translation. So, if you’re not using transformers, are you even in the game?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "parser.invoke(response_openai)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3d4b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['subject'], input_types={}, partial_variables={}, template='Tell me a joke about {subject}.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Tell me a joke about {subject}.\")    \n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb12079b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me a joke about computers.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"subject\": \"computers\", \"audience\": \"children\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b380566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are an experienced copywriter and an expert in transformers.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Give me the plan for a blog post given this information: Transformers are models that use self-attention...', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an experienced copywriter and an expert in {topic}.\"),\n",
    "    (\"human\", \"Give me the plan for a blog post given this information: {information}\")\n",
    "])\n",
    "\n",
    "model = ChatGroq(temperature=0.7, model=\"groq-llm-8k-chat-beta\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46117702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_engineer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
